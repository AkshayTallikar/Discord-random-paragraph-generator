{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Discord bot.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DA2pQ_iXuMg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "f84123a4-bf37-41a9-b59d-4320ee8f154a"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import discord\n",
        "from discord.ext import commands\n",
        "import asyncio\n",
        "import os\n",
        "import time\n",
        "import numpy\n",
        "import gpt_2_simple as gpt2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg2HxsjrtwkH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "fdbf7f5c-3a25-408b-aada-d63cefe326ba"
      },
      "source": [
        "!pip install discord\n",
        "!pip install gpt-2-simple"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: discord in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: discord.py>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from discord) (1.3.4)\n",
            "Requirement already satisfied: websockets!=7.0,!=8.0,!=8.0.1,<9.0,>=6.0 in /usr/local/lib/python3.6/dist-packages (from discord.py>=1.0.1->discord) (8.1)\n",
            "Requirement already satisfied: aiohttp<3.7.0,>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from discord.py>=1.0.1->discord) (3.6.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp<3.7.0,>=3.6.0->discord.py>=1.0.1->discord) (19.3.0)\n",
            "Requirement already satisfied: idna-ssl>=1.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp<3.7.0,>=3.6.0->discord.py>=1.0.1->discord) (1.1.0)\n",
            "Requirement already satisfied: chardet<4.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp<3.7.0,>=3.6.0->discord.py>=1.0.1->discord) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp<3.7.0,>=3.6.0->discord.py>=1.0.1->discord) (3.7.4.2)\n",
            "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp<3.7.0,>=3.6.0->discord.py>=1.0.1->discord) (3.0.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp<3.7.0,>=3.6.0->discord.py>=1.0.1->discord) (1.4.2)\n",
            "Requirement already satisfied: multidict<5.0,>=4.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp<3.7.0,>=3.6.0->discord.py>=1.0.1->discord) (4.7.6)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.6/dist-packages (from idna-ssl>=1.0; python_version < \"3.7\"->aiohttp<3.7.0,>=3.6.0->discord.py>=1.0.1->discord) (2.10)\n",
            "Requirement already satisfied: gpt-2-simple in /usr/local/lib/python3.6/dist-packages (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (1.18.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (4.41.1)\n",
            "Requirement already satisfied: toposort in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (1.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmQyb_RKX455",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "5fe1c4fa-af75-415b-d5af-3e66b7a838a2"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jul 21 19:19:33 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mef307i3t8tZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "c8660f5e-12bf-45ba-ebde-2f610d0740c3"
      },
      "source": [
        "gpt2.download_gpt2(model_name='345M')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 195Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 93.7Mit/s]                                                   \n",
            "Fetching hparams.json: 1.05Mit [00:00, 216Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:14, 98.6Mit/s]                                 \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 291Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 102Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 137Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0-0N_cWY0Fa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e48bb10c-5313-4345-9262-707d00da9563"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess,model_name='124M')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading pretrained model models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4XbAZAeaxDL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "8ea055d9-d12b-4be0-8add-e75fe563b71c"
      },
      "source": [
        "client = discord.Client()\n",
        "\n",
        "\n",
        "@client.event\n",
        "async def on_message(message):\n",
        "  if str(message.channel) == \"memes\" and message.content.startswith('.'):\n",
        "    if message.author.id != '711366974004920330':\n",
        "      prefix = message.content\n",
        "      text = gpt2.generate(sess,\n",
        "                         length=400,\n",
        "                         temperature=1.0,\n",
        "                         prefix=prefix,\n",
        "                         nsamples=1,\n",
        "                         batch_size=1,\n",
        "                         return_as_list=True,\n",
        "                         model_name = '124M'\n",
        "                         )\n",
        "      await message.channel.send(text[0])\n",
        "    if message.content.startswith('hello'):\n",
        "        await message.channel.send(\"hi\")\n",
        "    if str(message.channel) != \"zoom-codes\" and message.content.startswith(\"https\"):\n",
        "        await message.channel.purge(limit=1)\n",
        "        await message.channel.purge(limit=1)\n",
        "        await message.channel.send(\"Do not send this link in the channel\")\n",
        "\n",
        "\n",
        "Token = 'Put your token here'\n",
        "client.run(Token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ignoring exception in on_message\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/discord/client.py\", line 312, in _run_event\n",
            "    await coro(*args, **kwargs)\n",
            "  File \"<ipython-input-4-84f459a35b06>\", line 18, in on_message\n",
            "    await message.channel.send(text[0])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/discord/abc.py\", line 870, in send\n",
            "    data = await state.http.send_message(channel.id, content, tts=tts, embed=embed, nonce=nonce)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/discord/http.py\", line 225, in request\n",
            "    raise HTTPException(r, data)\n",
            "discord.errors.HTTPException: 400 Bad Request (error code: 50035): Invalid Form Body\n",
            "In content: Must be 2000 or fewer in length.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}
